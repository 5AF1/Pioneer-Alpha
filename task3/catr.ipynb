{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN0Muv10IPQO"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/5af1/Pioneer-Alpha/blob/master/task3/catr.ipynb\"\n",
        "target=\"_parent\">\n",
        "<!--- \"https://colab.research.google.com/github/saahiluppal/catr/blob/master/catr_demo.ipynb\" -->\n",
        "<img \n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" \n",
        "alt=\"Open In Colab\"/></a>\n",
        "\n",
        "<!--- This is an HTML comment in Markdown -->"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task3\n",
        "\n",
        "Run image captioning codebase and update the code for the Bangla dataset."
      ],
      "metadata": {
        "id": "OpbgUv4LHR1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drive mount\n",
        "\n",
        "Frist we mount the drive. The main data is stored in the following links. The drive links are made public. But if any problem arises please visit the following links.\n",
        "\n",
        "The Bangla Dataset: [BanglaLekhaImageCaptions](https://drive.google.com/drive/u/2/folders/10BCfOwDyroU69Nn61LeZic0c9lQVF74a).\n",
        "\n",
        "Trained model [Saved Weight](https://drive.google.com/drive/u/2/folders/1AA2e7AH-lZzy9zGoztZSSwnjoZDffmGF)"
      ],
      "metadata": {
        "id": "UVD5tl0xG-31"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPlnYms_jb63",
        "outputId": "c51d72e1-5ae6-4e9d-f593-3a0cd02e28f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone github repo\n",
        "\n",
        "Al three tasks are stored here in this repo. The main code repo for this task is a sub repo inside this repo. Minor changes were made here and there to properly load the dataset and save the weights.\n",
        "\n",
        "Major changes include:\n",
        "- Updating the coco.py file to read .png files and reading the image files names properly.\n",
        "- Changing the config.py file to save checkpoints in google drive"
      ],
      "metadata": {
        "id": "12jE9NpoIACV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nNwvp-LIPQQ",
        "outputId": "05f37f6e-a1c5-49a1-d135-0262b98dcb70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pioneer-Alpha'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 101 (delta 23), reused 22 (delta 18), pack-reused 65\u001b[K\n",
            "Receiving objects: 100% (101/101), 37.45 MiB | 13.88 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Submodule 'task3/catr' (https://github.com/5AF1/catr) registered for path 'task3/catr'\n",
            "Cloning into '/content/Pioneer-Alpha/task3/catr'...\n",
            "remote: Enumerating objects: 143, done.        \n",
            "remote: Counting objects: 100% (86/86), done.        \n",
            "remote: Compressing objects: 100% (50/50), done.        \n",
            "remote: Total 143 (delta 60), reused 48 (delta 36), pack-reused 57        \n",
            "Receiving objects: 100% (143/143), 3.05 MiB | 12.02 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Submodule path 'task3/catr': checked out 'f096715745a4c6a21bccaac82b5085511d900e38'\n"
          ]
        }
      ],
      "source": [
        "! git clone --recursive https://github.com/5AF1/Pioneer-Alpha.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic imports"
      ],
      "metadata": {
        "id": "r8uLfQIyMYCd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkmgcGf6nD-_"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "import requests, shutil, os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip Function"
      ],
      "metadata": {
        "id": "xHz5WCkhMczt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkGpoQhGjc68"
      },
      "outputs": [],
      "source": [
        "def my_unzip(archive,output,extract_here = False):\n",
        "    output = output/archive.stem if not extract_here else output\n",
        "    \n",
        "    os.makedirs(output,exist_ok=True)\n",
        "\n",
        "    with ZipFile(archive, 'r') as zip_ref:\n",
        "        zip_ref.extractall(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzipping the dataset.\n",
        "\n",
        "Here the data is unzipped"
      ],
      "metadata": {
        "id": "vGgwe60KMhM9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1F10cXos__e"
      },
      "outputs": [],
      "source": [
        "content = Path(\"/content\")\n",
        "drive_shortcut = Path('drive/.shortcut-targets-by-id/10BCfOwDyroU69Nn61LeZic0c9lQVF74a/paper dataset/')\n",
        "image_zip_file = content/drive_shortcut/'images.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YggCKpsl0-3X"
      },
      "outputs": [],
      "source": [
        "my_unzip(image_zip_file,content/'Pioneer-Alpha/task3/catr',extract_here=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and saving functions for json files"
      ],
      "metadata": {
        "id": "Sp5NSadcMym9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DmIMeEV2bSs"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def load_data(file_):\n",
        "    with open(file_, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    return data\n",
        "\n",
        "def save_data(file_,data):\n",
        "    os.makedirs(file_.parent,exist_ok=True)\n",
        "    with open(file_,'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# json file structure\n",
        "\n",
        "For training a proper json file has the following structure\n",
        "```python\n",
        "captions_2017 = {\n",
        "                \"info\":INFO_DICT,\n",
        "                \"licenses\":LICENSES_LIST,\n",
        "                \"images\":images_list,\n",
        "                \"annotations\":annotations_list,\n",
        "    }\n",
        "```\n",
        "Now the image_list and annotation list holds a list of dictionary of the following structure.\n",
        "```python\n",
        "image_dict = {\n",
        "            \"file_name\": \"000000000042.jpg\",\n",
        "            \"height\": 478,\n",
        "            \"width\": 640,\n",
        "            \"id\": 42\n",
        "}\n",
        "\n",
        "annotations_dict = {\n",
        "            \"image_id\": 74,\n",
        "            \"id\": 145996,\n",
        "            \"caption\": \"A picture of a dog laying on the ground.\"\n",
        "}\n",
        "```\n",
        "The INFO_DICT has the following structure\n",
        "```python\n",
        "INFO_DICT = {\n",
        "        \"description\": \"BanglaLekhaImageCaptions Dataset\",\n",
        "        \"url\": \"https://data.mendeley.com/datasets/rxxch9vw59/2\",\n",
        "        \"version\": \"2.0\",\n",
        "        \"year\": 2019,\n",
        "        \"contributor\": \"Nafees Mansoor, Abrar Hasin Kamal, Nabeel Mohammed, Sifat Momen, Md Matiur Rahman\",\n",
        "        \"date_created\": \"2019/07/28\"\n",
        "    }\n",
        "```\n",
        "\n",
        "Now our given dataset json file has the following structure\n",
        "```python\n",
        "caption = [\n",
        "    {\n",
        "        'caption': ['রাস্তা দিয়ে কতকগুলো শিশু সারিবদ্ধ ভাবে হেঁটে যাচ্ছে।','কিছু বাচ্চা গ্রামের রাস্তা দিয়ে হাতে যাচ্ছে এবং সাথে একজন পুরুষ মানুষ।'],\n",
        "        'filename': '981.png'\n",
        "    },\n",
        "    {},{},{},...\n",
        "]\n",
        "```\n",
        "\n",
        "So given the caption.json file we create 3 other json files. They are\n",
        "1. captions_train2017.json\n",
        "1. captions_val2017.json\n",
        "1. captions_test2017.json"
      ],
      "metadata": {
        "id": "PmkTGIQHNA7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Two constants variables for creating the json files. "
      ],
      "metadata": {
        "id": "uwjspEBGThlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INFO_DICT = {\n",
        "        \"description\": \"BanglaLekhaImageCaptions Dataset\",\n",
        "        \"url\": \"https://data.mendeley.com/datasets/rxxch9vw59/2\",\n",
        "        \"version\": \"2.0\",\n",
        "        \"year\": 2019,\n",
        "        \"contributor\": \"Nafees Mansoor, Abrar Hasin Kamal, Nabeel Mohammed, Sifat Momen, Md Matiur Rahman\",\n",
        "        \"date_created\": \"2019/07/28\"\n",
        "    }\n",
        "\n",
        "LICENSES_LIST = []"
      ],
      "metadata": {
        "id": "PO__bnYm6D5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First we load the data from caption.json\n",
        "---"
      ],
      "metadata": {
        "id": "a4FoMqL1O_Zb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzP-wgmo19E-"
      },
      "outputs": [],
      "source": [
        "caption_path = Path('/content/Pioneer-Alpha/task3/bl_cap/captions.json')\n",
        "caption_data = load_data(caption_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the indices of the caption list so that train val test distribution can be done\n",
        "---"
      ],
      "metadata": {
        "id": "F7nyIT60PFvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "indices = np.arange(len(caption_data))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "split_frac_size = [.7,.2,.1]\n",
        "split_frac_points = np.cumsum(split_frac_size)\n",
        "split_frac_points = split_frac_points[:-1]\n",
        "\n",
        "train_indices, val_indices, test_indices = np.split(indices,[round( len(indices)*frac ) for frac in split_frac_points])\n",
        "len(train_indices), len(val_indices), len(test_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNB_rpPgZ3cx",
        "outputId": "4eb0096c-437a-4c15-9943-cb765ab2f977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6408, 1831, 915)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_8UBhUMxok1",
        "outputId": "04c27180-885c-4b25-85c3-3babf29e5e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8874, 2214, 4112, ..., 4082, 1486, 3678])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data\n",
        "---"
      ],
      "metadata": {
        "id": "2Wn46WuzPj5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dict_list = [caption_data[i] for i in train_indices]\n",
        "val_dict_list = [caption_data[i] for i in val_indices]\n",
        "test_dict_list = [caption_data[i] for i in test_indices]"
      ],
      "metadata": {
        "id": "9tIs74qSnzHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a function to generate the json files and copy the image files.\n",
        "\n",
        "A coco folder is created in the code repo and it needs 3 folders for the training to work. They are\n",
        "1. annotations (to store the json files captions_train2017.json and captions_val2017.json)\n",
        "1. train2017 (to store the images for training)\n",
        "1. val2017 (to store the images for validation)"
      ],
      "metadata": {
        "id": "hn428ryZPoWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_annotation_json(data_dict_list,images_path,coco_path,tvt='train'):\n",
        "    images_list = []\n",
        "    annotations_list = []\n",
        "\n",
        "\n",
        "    # Traverse each data_dict in the given list\n",
        "    for data_dict in tqdm(data_dict_list,desc = tvt):\n",
        "        img_file_name = data_dict['filename']\n",
        "        caption_list = data_dict['caption']\n",
        "\n",
        "        id_no = int(img_file_name.split('.')[0])\n",
        "        img_src = Image.open(images_path/img_file_name)\n",
        "\n",
        "        image_dict = {\n",
        "            \"file_name\": img_file_name.zfill(5+4),\n",
        "            \"height\": img_src.height,\n",
        "            \"width\": img_src.width,\n",
        "            \"id\": id_no\n",
        "        }\n",
        "        # Iterate over each caption to create seperate annotations_list elements\n",
        "        for i,caption in enumerate(caption_list):\n",
        "            annotations_dict = {\n",
        "                \"image_id\": id_no,\n",
        "                \"id\": id_no*1000+i+1,\n",
        "                \"caption\": caption\n",
        "            }\n",
        "            annotations_list.append(annotations_dict)\n",
        "        \n",
        "        images_list.append(image_dict)\n",
        "\n",
        "        #Copying the image to the proper directory\n",
        "        src_path = images_path/img_file_name\n",
        "        dst_path = coco_path/f'{tvt}2017'/image_dict['file_name']\n",
        "\n",
        "        os.makedirs(dst_path.parent,exist_ok=True)\n",
        "        shutil.copy(src_path,dst_path)\n",
        "\n",
        "    # Saving the json file\n",
        "    captions_2017 = {\n",
        "                \"info\":INFO_DICT,\n",
        "                \"licenses\":LICENSES_LIST,\n",
        "                \"images\":images_list,\n",
        "                \"annotations\":annotations_list,\n",
        "    }\n",
        "    captions_2017_path = coco_path/'annotations'/f'captions_{tvt}2017.json'\n",
        "    save_data(captions_2017_path,captions_2017)\n",
        "\n"
      ],
      "metadata": {
        "id": "L1jjUmJrkjqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = Path('/content/Pioneer-Alpha/task3/catr/images')\n",
        "coco_path = Path('/content/Pioneer-Alpha/task3/coco/')\n",
        "\n",
        "create_annotation_json(train_dict_list,images_path,coco_path,tvt='train')\n",
        "create_annotation_json(val_dict_list,images_path,coco_path,tvt='val')\n",
        "create_annotation_json(test_dict_list,images_path,coco_path,tvt='test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy_q4Hln_UbQ",
        "outputId": "77a7fde7-00f6-482d-9183-e98a1e186642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 6408/6408 [00:56<00:00, 114.34it/s]\n",
            "val: 100%|██████████| 1831/1831 [00:16<00:00, 108.31it/s]\n",
            "test: 100%|██████████| 915/915 [00:08<00:00, 109.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1KTtKviO5_43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change directory\n",
        "Go to the catr directory for training and prediction"
      ],
      "metadata": {
        "id": "hKCVQi69RabI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgAmwSXB6rSE",
        "outputId": "3b87f2e3-7b37-4962-b461-5eb8e5819ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Pioneer-Alpha/task3/catr\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Pioneer-Alpha/task3/catr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgtIQH9q9-oz",
        "outputId": "f309f1f2-888b-4505-f0fa-936bbeb3f925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.21.6)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (4.11.4)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 4)) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r requirements.txt (line 4)) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction for the model I trained."
      ],
      "metadata": {
        "id": "9_eFAa5zSAqY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjVwH3wP9dPE",
        "outputId": "f8e2fb91-023c-40c4-f945-c254d5281806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for checkpoint.\n",
            "Found checkpoint! Loading!\n",
            "Loading Checkpoint...\n"
          ]
        }
      ],
      "source": [
        "!python predict.py --path images/1896.png --v v25 --checkpoint ../../../drive/.shortcut-targets-by-id/1AA2e7AH-lZzy9zGoztZSSwnjoZDffmGF/catr/checkpoint.pth\n",
        "#12 1105"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I trained the model for 30 epochs over 1.5 days in colab\n",
        "\n",
        "The weights are stored in google drive."
      ],
      "metadata": {
        "id": "D9IKQyW3RnbQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_Z7ruFx93B_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d087ec35-8da2-4f4f-e233-9b422ff699d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Device: cuda\n",
            "Number of params: 83959866\n",
            "Train: 12815\n",
            "Valid: 3662\n",
            "Start Training..\n",
            "Epoch: 0\n",
            "100% 400/400 [11:52<00:00,  1.78s/it]\n",
            "Training Loss: 1.4886506993323565\n",
            "100% 115/115 [01:42<00:00,  1.13it/s]\n",
            "Validation Loss: 0.595809015761251\n",
            "\n",
            "Epoch: 1\n",
            "100% 400/400 [11:57<00:00,  1.79s/it]\n",
            "Training Loss: 0.5492002014070749\n",
            "100% 115/115 [01:42<00:00,  1.13it/s]\n",
            "Validation Loss: 0.46083275598028434\n",
            "\n",
            "Epoch: 2\n",
            "100% 400/400 [11:59<00:00,  1.80s/it]\n",
            "Training Loss: 0.4535487465560436\n",
            "100% 115/115 [01:42<00:00,  1.12it/s]\n",
            "Validation Loss: 0.3982638268367104\n",
            "\n",
            "Epoch: 3\n",
            "100% 400/400 [11:58<00:00,  1.80s/it]\n",
            "Training Loss: 0.4036784271150827\n",
            "100% 115/115 [01:42<00:00,  1.12it/s]\n",
            "Validation Loss: 0.367786269084267\n",
            "\n",
            "Epoch: 4\n",
            "100% 400/400 [11:58<00:00,  1.80s/it]\n",
            "Training Loss: 0.37383348800241945\n",
            "100% 115/115 [01:42<00:00,  1.12it/s]\n",
            "Validation Loss: 0.3467674408269965\n",
            "\n",
            "Epoch: 5\n",
            "100% 400/400 [11:56<00:00,  1.79s/it]\n",
            "Training Loss: 0.35282120361924174\n",
            "100% 115/115 [01:45<00:00,  1.09it/s]\n",
            "Validation Loss: 0.3321814183307731\n",
            "\n",
            "Epoch: 6\n",
            "100% 400/400 [11:56<00:00,  1.79s/it]\n",
            "Training Loss: 0.33608638048171996\n",
            "100% 115/115 [01:45<00:00,  1.09it/s]\n",
            "Validation Loss: 0.3196830752103225\n",
            "\n",
            "Epoch: 7\n",
            "100% 400/400 [11:59<00:00,  1.80s/it]\n",
            "Training Loss: 0.3221745680272579\n",
            "100% 115/115 [01:43<00:00,  1.12it/s]\n",
            "Validation Loss: 0.3111303880162861\n",
            "\n",
            "Epoch: 8\n",
            "100% 400/400 [11:58<00:00,  1.80s/it]\n",
            "Training Loss: 0.31029137291014197\n",
            "100% 115/115 [01:42<00:00,  1.13it/s]\n",
            "Validation Loss: 0.30247031178163447\n",
            "\n",
            "Epoch: 9\n",
            "100% 400/400 [11:58<00:00,  1.80s/it]\n",
            "Training Loss: 0.30014767426997424\n",
            "100% 115/115 [01:42<00:00,  1.12it/s]\n",
            "Validation Loss: 0.29696493006270863\n",
            "\n",
            "Epoch: 10\n",
            "100% 400/400 [11:59<00:00,  1.80s/it]\n",
            "Training Loss: 0.290415348559618\n",
            "100% 115/115 [01:44<00:00,  1.10it/s]\n",
            "Validation Loss: 0.2920345013556273\n",
            "\n",
            "Epoch: 11\n",
            "100% 400/400 [11:58<00:00,  1.80s/it]\n",
            "Training Loss: 0.2821755048260093\n",
            "100% 115/115 [01:44<00:00,  1.10it/s]\n",
            "Validation Loss: 0.28703797083833943\n",
            "\n",
            "Epoch: 12\n",
            "100% 400/400 [11:58<00:00,  1.80s/it]\n",
            "Training Loss: 0.2740091497823596\n",
            "100% 115/115 [01:42<00:00,  1.12it/s]\n",
            "Validation Loss: 0.2857387169547703\n",
            "\n",
            "Epoch: 13\n",
            "100% 400/400 [12:00<00:00,  1.80s/it]\n",
            "Training Loss: 0.2671720929816365\n",
            "100% 115/115 [01:43<00:00,  1.11it/s]\n",
            "Validation Loss: 0.27941629873669666\n",
            "\n",
            "Epoch: 14\n",
            " 96% 382/400 [11:27<00:31,  1.77s/it]"
          ]
        }
      ],
      "source": [
        "!python -W ignore main.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -W ignore main.py"
      ],
      "metadata": {
        "id": "LcYiAD9cRfOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a6ee59-4a3e-4aec-d51e-f6ae2e2d1295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100% 171M/171M [00:01<00:00, 143MB/s]\n",
            "Number of params: 83959866\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 929kB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 26.0kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 562kB/s]\n",
            "Train: 12815\n",
            "Valid: 3662\n",
            "Loading Checkpoint...\n",
            "Start Training..\n",
            "Epoch: 17\n",
            "100% 400/400 [11:42<00:00,  1.76s/it]\n",
            "Training Loss: 0.2401186903938651\n",
            "100% 115/115 [01:40<00:00,  1.15it/s]\n",
            "Validation Loss: 0.2744591354028038\n",
            "\n",
            "Epoch: 18\n",
            "100% 400/400 [11:46<00:00,  1.77s/it]\n",
            "Training Loss: 0.2336150925606489\n",
            "100% 115/115 [01:42<00:00,  1.13it/s]\n",
            "Validation Loss: 0.2736491858959198\n",
            "\n",
            "Epoch: 19\n",
            " 28% 110/400 [03:22<08:25,  1.74s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -W ignore main.py"
      ],
      "metadata": {
        "id": "NBGz22PkWH8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5635771e-665b-48bd-f34d-1bfdff4a4647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100% 171M/171M [00:00<00:00, 253MB/s]\n",
            "Number of params: 83959866\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 266kB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 24.8kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 489kB/s]\n",
            "Train: 12815\n",
            "Valid: 3662\n",
            "Loading Checkpoint...\n",
            "Start Training..\n",
            "Epoch: 20\n",
            "100% 400/400 [11:27<00:00,  1.72s/it]\n",
            "Training Loss: 0.1950124372728169\n",
            "100% 115/115 [01:42<00:00,  1.13it/s]\n",
            "Validation Loss: 0.2765206084303234\n",
            "\n",
            "Epoch: 21\n",
            "100% 400/400 [11:30<00:00,  1.73s/it]\n",
            "Training Loss: 0.1873413324728608\n",
            "100% 115/115 [01:40<00:00,  1.15it/s]\n",
            "Validation Loss: 0.2793176759844241\n",
            "\n",
            "Epoch: 22\n",
            "100% 400/400 [11:32<00:00,  1.73s/it]\n",
            "Training Loss: 0.18051403019577264\n",
            "100% 115/115 [01:40<00:00,  1.14it/s]\n",
            "Validation Loss: 0.2808492205713106\n",
            "\n",
            "Epoch: 23\n",
            "100% 400/400 [11:31<00:00,  1.73s/it]\n",
            "Training Loss: 0.20310788014903663\n",
            "100% 115/115 [01:41<00:00,  1.14it/s]\n",
            "Validation Loss: 0.27727129964724834\n",
            "\n",
            "Epoch: 24\n",
            "100% 400/400 [11:32<00:00,  1.73s/it]\n",
            "Training Loss: 0.20093530248850583\n",
            "100% 115/115 [01:39<00:00,  1.16it/s]\n",
            "Validation Loss: 0.27683889347573987\n",
            "\n",
            "Epoch: 25\n",
            "100% 400/400 [11:30<00:00,  1.73s/it]\n",
            "Training Loss: 0.19876824237406254\n",
            "100% 115/115 [01:40<00:00,  1.15it/s]\n",
            "Validation Loss: 0.27666560139345087\n",
            "\n",
            "Epoch: 26\n",
            "100% 400/400 [11:30<00:00,  1.73s/it]\n",
            "Training Loss: 0.19726547004655004\n",
            "100% 115/115 [01:41<00:00,  1.14it/s]\n",
            "Validation Loss: 0.27761682608853216\n",
            "\n",
            "Epoch: 27\n",
            "100% 400/400 [11:32<00:00,  1.73s/it]\n",
            "Training Loss: 0.1953416195139289\n",
            "100% 115/115 [01:40<00:00,  1.15it/s]\n",
            "Validation Loss: 0.27803275183491083\n",
            "\n",
            "Epoch: 28\n",
            "100% 400/400 [11:31<00:00,  1.73s/it]\n",
            "Training Loss: 0.19334109948948025\n",
            "100% 115/115 [01:41<00:00,  1.14it/s]\n",
            "Validation Loss: 0.2790162442818932\n",
            "\n",
            "Epoch: 29\n",
            "100% 400/400 [11:32<00:00,  1.73s/it]\n",
            "Training Loss: 0.19175222055986524\n",
            "100% 115/115 [01:41<00:00,  1.14it/s]\n",
            "Validation Loss: 0.27916148071703706\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thank you."
      ],
      "metadata": {
        "id": "VcDsUbV5SOvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VUSsw8Hqis-r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "catr.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.3 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "66355f80a275565a89a0ec38932205206fadf83098ce3fb68526a4d22f542f4f"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}